{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "5_AttackNNWithPytorch.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Maupin1991/ML_pytorch_tutorial/blob/master/5_AttackNNWithPytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFklpo0xmCQU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch import optim\n",
        "\n",
        "\n",
        "np.random.seed(99)\n",
        "torch.manual_seed(10);\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"Using device:  \", device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zol5od7UmMV2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Model class\n",
        "class Network(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(784, 256)\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.fc3 = nn.Linear(128, 64)\n",
        "        self.fc4 = nn.Linear(64, 10)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # make sure input tensor is flattened\n",
        "        x = x.view(x.shape[0], -1)\n",
        "        \n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = torch.relu(self.fc3(x))\n",
        "        x = torch.log_softmax(self.fc4(x), dim=1)\n",
        "        \n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lz7MmoQJmQsa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define a transform\n",
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "n_train = 10000\n",
        "n_test = 1000\n",
        "# validation set is 20% of the training set\n",
        "valid_size = 0.2\n",
        "\n",
        "epochs = 30\n",
        "\n",
        "# Download and load the data\n",
        "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, \n",
        "                          train=True, transform=transform)\n",
        "testset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, \n",
        "                          train=False, transform=transform)\n",
        "\n",
        "# Splitting train/validation and testing set\n",
        "\n",
        "# training set\n",
        "train_idxs = np.arange(len(trainset))\n",
        "np.random.shuffle(train_idxs)\n",
        "train_idxs = train_idxs[:n_train].tolist()\n",
        "\n",
        "# subsample validation set from training set\n",
        "n_valid = int(np.floor(n_train * valid_size))\n",
        "valid_idxs = train_idxs[:n_valid]\n",
        "train_idxs = train_idxs[n_valid:]\n",
        "\n",
        "# testing set\n",
        "test_idxs = np.arange(len(testset))\n",
        "np.random.shuffle(test_idxs)\n",
        "test_idxs = test_idxs[:n_test].tolist()\n",
        "\n",
        "# extract only the selected indices\n",
        "train_subset = torch.utils.data.Subset(trainset, train_idxs)\n",
        "valid_subset = torch.utils.data.Subset(trainset, valid_idxs)\n",
        "test_subset = torch.utils.data.Subset(testset, test_idxs)\n",
        "\n",
        "# data loader (finally)\n",
        "trainloader = torch.utils.data.DataLoader(train_subset, batch_size=32)\n",
        "validloader = torch.utils.data.DataLoader(valid_subset, batch_size=32)\n",
        "testloader = torch.utils.data.DataLoader(test_subset, batch_size=32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecJWOm6cmZGf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.NLLLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7X5jYT5VmaFm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = Network()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.03)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QX5blfgBmdg7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net.to(device)\n",
        "train_losses, valid_losses = [], []\n",
        "\n",
        "# train model and evaluate with validation set\n",
        "for e in range(epochs):\n",
        "    running_loss = 0\n",
        "    for images, labels in trainloader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        log_ps = net(images)\n",
        "        loss = criterion(log_ps, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "        \n",
        "    else:\n",
        "        valid_loss = 0\n",
        "        accuracy = 0\n",
        "        \n",
        "        # Turn off gradients for validation, saves memory and computations\n",
        "        with torch.no_grad():\n",
        "            net.eval()\n",
        "            for images, labels in validloader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                log_ps = net(images)\n",
        "                valid_loss += criterion(log_ps, labels)\n",
        "                \n",
        "                ps = torch.exp(log_ps)\n",
        "                top_p, top_class = ps.topk(1, dim=1)\n",
        "                equals = top_class == labels.view(*top_class.shape)\n",
        "                accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
        "        \n",
        "        net.train()\n",
        "        \n",
        "        train_losses.append(running_loss/len(trainloader))\n",
        "        valid_losses.append(valid_loss/len(validloader))\n",
        "\n",
        "        print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
        "              \"Training Loss: {:.3f}.. \".format(train_losses[-1]),\n",
        "              \"Validation Loss: {:.3f}.. \".format(valid_losses[-1]),\n",
        "              \"Validation Accuracy: {:.3f}\".format(accuracy/len(validloader)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFl_3MLKmg0D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# evaluate on testing set\n",
        "with torch.no_grad():\n",
        "    net.eval()\n",
        "    test_loss = 0\n",
        "    accuracy = 0\n",
        "\n",
        "    for images, labels in testloader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        output = net(images)\n",
        "        test_loss += criterion(output, labels)\n",
        "\n",
        "        top_p, top_class = output.topk(1, dim=1)\n",
        "        equals = top_class == labels.view(*top_class.shape)\n",
        "        accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
        "\n",
        "    print(\"Test Accuracy: {:.3f}\".format(accuracy/len(testloader)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7MoD5DKuCZj",
        "colab_type": "text"
      },
      "source": [
        "We are going to use the [FGSM attack](https://arxiv.org/abs/1412.6572) to fool our trained network. \n",
        "\n",
        "**Code and details are available [in this GitHub repo](https://github.com/1Konny/FGSM)**.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "![FGSM example](https://raw.githubusercontent.com/1Konny/FGSM/master/misc/overview.PNG)\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "We are going to implement the following expression:\n",
        "\n",
        "\n",
        " $$\\huge{x_{adv} = x_{benign} + \\varepsilon * \\text{sign}(\\nabla_{x_{benign}}J(\\theta, x_{benign}, y))}$$\n",
        " \n",
        " Note that we can distinguish 2 possible directions:\n",
        " \n",
        " * untargeted: we just want to move the point where the loss is maximum. We can do so by computing the loss with the original labels and the output of the network and maximizing it. \n",
        " \n",
        " * targeted: we want to minimize the loss with respect to a particular class. We can do so by computing the loss with the target labels and the output of the network and minimizing it.\n",
        " \n",
        " \n",
        " **Remember that we are dealing with image data**. This means that we should limit the perturbation in the image domain, so when adding $\\varepsilon$ to each pixel we should clip values to the right range."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NbwLQGUojB_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.autograd import Variable\n",
        "\n",
        "def fgsm(x, y, net, criterion, targeted=False, eps=0.03, x_val_min=-1, x_val_max=1):\n",
        "    x_adv = Variable(x.data, requires_grad=True)\n",
        "    h_adv = net(x_adv)\n",
        "    if targeted:\n",
        "        cost = criterion(h_adv, y)\n",
        "    else:\n",
        "        cost = -criterion(h_adv, y)\n",
        "\n",
        "    net.zero_grad()\n",
        "    if x_adv.grad is not None:\n",
        "        x_adv.grad.data.fill_(0)\n",
        "    cost.backward()\n",
        "\n",
        "    x_adv.grad.sign_()\n",
        "    x_adv = x_adv - eps*x_adv.grad\n",
        "    x_adv = torch.clamp(x_adv, x_val_min, x_val_max)\n",
        "\n",
        "\n",
        "    h = net(x)\n",
        "    h_adv = net(x_adv)\n",
        "\n",
        "    return x_adv, h_adv, h"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvFVjX0xu-RH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x, y = next(iter(testloader))\n",
        "x, y = x.to(device), y.to(device)\n",
        "x_adv, h_adv, h = fgsm(x, y, net, criterion, eps=0.08, x_val_min=0)\n",
        "x_adv = x_adv.detach();"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eud4rDTgwJyA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "images = x\n",
        "images_adv, labels = x_adv, y\n",
        "classes = range(10)\n",
        "\n",
        "# move model inputs to cuda, if GPU available\n",
        "images_cuda = images.to(device)\n",
        "images_adv_cuda = images_adv.to(device)\n",
        "\n",
        "# get sample outputs\n",
        "output = net(images_cuda)\n",
        "output_adv = net(images_adv_cuda)\n",
        "# convert output probabilities to predicted class\n",
        "_, preds_tensor = torch.max(output, 1)\n",
        "_, preds_tensor_adv = torch.max(output_adv, 1)\n",
        "preds = np.squeeze(preds_tensor.cpu().numpy())\n",
        "preds_adv = np.squeeze(preds_tensor_adv.cpu().numpy())\n",
        "# plot the images in the batch, along with predicted and true labels\n",
        "fig = plt.figure(figsize=(20, 3))\n",
        "\n",
        "images = images.cpu().numpy()\n",
        "images_adv = images_adv.cpu().numpy()\n",
        "\n",
        "n_images = 10\n",
        "\n",
        "for idx in range(n_images):\n",
        "    ax = fig.add_subplot(2, n_images, idx+1, xticks=[], yticks=[])\n",
        "    plt.imshow(images[idx][0, :, :], interpolation='nearest', cmap='gray_r')\n",
        "    plt.axis(\"off\")\n",
        "    ax.set_title(\"{} ({})\".format(classes[preds[idx]], classes[labels[idx]]),\n",
        "                 color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))\n",
        "    \n",
        "for idx in range(n_images):\n",
        "    ax = fig.add_subplot(2, n_images, n_images+idx+1, xticks=[], yticks=[])\n",
        "    plt.imshow(images_adv[idx][0, :, :], interpolation='nearest', cmap='gray_r')\n",
        "    plt.axis(\"off\")\n",
        "    ax.set_title(\"{} ({})\".format(classes[preds_adv[idx]], classes[labels[idx]]),\n",
        "                 color=(\"green\" if preds_adv[idx]==labels[idx].item() else \"red\"))\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wMxV-Q3_zvhc",
        "colab_type": "text"
      },
      "source": [
        "## Challenge\n",
        "\n",
        "Plot accuracy with respect to the maximum perturbation $\\varepsilon$.\n",
        "\n",
        "This kind of plot is called **security evaluation curve**. It displays how much accuracy drops with increasing values of worst-case (adversarial) perturbation.\n",
        "\n",
        "You should end up with a plot similar to the ones displayed [here](https://advx-secml.pluribus-one.it/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zjLA6m-0VRr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for loop, with several values of eps\n",
        "# iterate through all the testing set\n",
        "\n",
        "eps_values = np.arange(0, 1, 0.05)\n",
        "for i in range(len(eps_values)):\n",
        "    for imgs, labels in testloader:\n",
        "        # generate adv images\n",
        "        \n",
        "        # obtain output\n",
        "        \n",
        "        pass\n",
        "        \n",
        "    # compute accuracy\n",
        "\n",
        "    # store accuracy\n",
        "        \n",
        "    pass\n",
        "\n",
        "# plot curve"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmbamTwH0cxS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# now try to add regularization and display again the security evaluation curve\n",
        "\n",
        "# dropout network class\n",
        "\n",
        "# optimizer with weight decay\n",
        "\n",
        "# plot accuracy again"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}